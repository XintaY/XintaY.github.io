<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#0078E7"><meta name="author" content="Xinta Yang"><meta name="copyright" content="Xinta Yang"><meta name="generator" content="Hexo 6.3.0"><meta name="theme" content="hexo-theme-yun"><title>Course STAT 888 - A first exposure to causal inference | </title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/star-markdown-css@0.4.1/dist/yun/yun-markdown.min.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/prism-theme-vars/base.css"><script src="https://fastly.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".markdown-body img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script type="module">import { renderKatex } from '/js/utils.js'
document.addEventListener("DOMContentLoaded", () => {
  renderKatex({
    ...{},
    ...true?.options,
  });
});</script><link rel="icon" type="image/png" href="/xy.png"><link rel="mask-icon" href="/xy.png" color="#0078E7"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="preconnect" href="https://fastly.jsdelivr.net/npm/" crossorigin><script id="yun-config">
    window.Yun = {}
    window.CONFIG = {"hostname":"example.com","root":"/","title":"懒猫的云间小筑","version":"1.10.9","mode":"light","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}.","hits":"${hits} results found","hits_time":"${hits} results found in ${time} ms"},"anonymous_image":"https://cdn.yunyoujun.cn/img/avatar/none.jpg","vendors":{"host":"https://fastly.jsdelivr.net/npm/","darken":"https://fastly.jsdelivr.net/npm/darken@1.5.0"}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/hexo-theme-yun.js" type="module"></script><!-- Google Tag Manager --><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-M9KWR9L');</script><!-- End Google Tag Manager --><meta name="description" content="This post is for my STAT 888 course taken at UW-Madison where we study causal inference. As this is my first exposure to the subject, I will not propose anything new; instead, the post merely document">
<meta property="og:type" content="article">
<meta property="og:title" content="Course STAT 888 - A first exposure to causal inference">
<meta property="og:url" content="http://example.com/2022/10/29/causal-inference/index.html">
<meta property="og:site_name">
<meta property="og:description" content="This post is for my STAT 888 course taken at UW-Madison where we study causal inference. As this is my first exposure to the subject, I will not propose anything new; instead, the post merely document">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/tikz/1.png">
<meta property="og:image" content="http://example.com/tikz/2.png">
<meta property="article:published_time" content="2022-10-29T15:08:42.066Z">
<meta property="article:modified_time" content="2022-11-13T05:12:17.884Z">
<meta property="article:author" content="Xinta Yang">
<meta property="article:tag" content="causal inference">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/tikz/1.png"><script>(function() {
  if (CONFIG.mode !== 'auto') return
  const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
  const setting = localStorage.getItem('darken-mode') || 'auto'
  if (setting === 'dark' || (prefersDark && setting !== 'light'))
    document.documentElement.classList.toggle('dark', true)
})()</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head><body><script src="https://code.iconify.design/2/2.1.1/iconify.min.js"></script><script>// Define global variable
IconifyProviders = {
  // Empty prefix: overwrite default API provider configuration
  '': {
    // Use custom API first, use Iconify public API as backup
    resources: [
        'https://api.iconify.design',
    ],
    // Wait for 1 second before switching API hosts
    rotate: 1000,
  },
};</script><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js" type="module"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="Table of Contents"><span class="icon iconify" data-icon="ri:list-ordered"></span></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="Overview"><span class="icon iconify" data-icon="ri:passport-line"></span></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="Xinta Yang"><img width="96" loading="lazy" src="/images/1.png" alt="Xinta Yang"></a><div class="site-author-name"><a href="/about/">Xinta Yang</a></div><span class="site-name"></span><sub class="site-subtitle">Welcome to my site! (The characters on the cover page are "lazy cat's cozy home amongst the clouds")</sub><div class="site-description"></div></div><br><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="Home"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:home-4-line"></span></span></a><div class="site-state-item"><a href="mailto:xinta.yang@wisc.edu"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:mail-line"></span></span></a></div><div class="site-state-item"><a target="_blank" rel="noopener" href="https://github.com/XintaY"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:github-line"></span></span></a></div><a class="site-state-item hty-icon-button" href="/tags/" title="Tags"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:bookmark-line"></span></span></a></nav><!--hr(style="margin-bottom:0.5rem")--></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Brief-Summary-of-Causal-Inference"><span class="toc-number">1.</span> <span class="toc-text">Brief Summary of Causal Inference</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Potential-outcomes"><span class="toc-number">1.1.</span> <span class="toc-text">Potential outcomes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Graphical-model-SWIG"><span class="toc-number">1.2.</span> <span class="toc-text">Graphical model SWIG</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Learn-Causal-Inference-via-Papers"><span class="toc-number">2.</span> <span class="toc-text">Learn Causal Inference via Papers</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article" style="--smc-primary:#0078E7;"><link itemprop="mainEntityOfPage" href="http://example.com/2022/10/29/causal-inference/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="Xinta Yang"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Course STAT 888 - A first exposure to causal inference</h1><div class="post-meta"><div class="post-time"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-line"></span></span> <time title="Created: 2022-10-29 10:08:42" itemprop="dateCreated datePublished" datetime="2022-10-29T10:08:42-05:00">2022-10-29</time></div><div class="post-classify"><span class="post-tag"><a class="tag-item" href="/tags/causal-inference/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:bookmark-line"></span></span><span class="tag-name">causal inference</span></a></span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body"><br>

<p>To be continued…</p>
<blockquote>
<h2 id="Brief-Summary-of-Causal-Inference"><a href="#Brief-Summary-of-Causal-Inference" class="headerlink" title="Brief Summary of Causal Inference"></a>Brief Summary of Causal Inference</h2></blockquote>
<h3 id="Potential-outcomes"><a href="#Potential-outcomes" class="headerlink" title="Potential outcomes"></a>Potential outcomes</h3><p> 
Suppose random variable $Y$ is the outcome of an experiment, and random variable $A$ is the corresponding treatment. We assume $\textbf{\textit{consistency}}$, i.e., $$Y(\omega) = Y_A(\omega)$$ We note that each treatment level $a$ associates with a random variable $Y_a$. To be more clear, suppose at event instance $\omega$, we assign treatment $A(\omega) = a$, then consistency says we assume $Y(\omega) = Y_a(\omega)$.
Another important assumption is $\textbf{\textit{exchangeability}}$, i.e., $$Y_a \perp A$$ for all $a \in A$. This says knowing what treatment level assigned does not provide any information about how the subject would react under different treatments. This is usually achieved by randomly assign treatments to subjects. 
We note that not all $Y_a(\omega)$ is observed. For example, if we assign $A = 1$ to subject $\omega$, then we can observe $Y_1(\omega)$, but can't observe $Y_0(\omega)$. 
It's also important to point out that $E(Y_a)$ does not necessarily equal to $E(Y\,|\, A=a)$. For example, 
$$
\begin{array}{c|c|c|c}
X & A & Y & P(x, a, y) \\
\hline
0 & 0 & 0 & 1/8 \\
0 & 0 & 1 & 1/8 \\
0 & 1 & 0 & 1/8 \\
0 & 1 & 1 & 1/8 \\
0 & 1 & 1 & 1/8 \\
1 & 0 & 0 & 25/128 \\
1 & 0 & 1 & 15/128 \\
1 & 1 & 0 & 15/128 \\
1 & 1 & 1 & 9/128
\end{array}
$$
and we also assume here that the potential outcome is invariant to treatment assigned, i.e., $Y_0 = Y_1$. 
By consistency and invariance, we have $Y = Y_0 = Y_1$. 
Hence, $$\begin{align*}
EY_1 &= EY_0 = EY \\
&= \sum_y y\cdot P(Y=y) \\
&= \sum_y y\cdot \sum_{a, x} P(a, x, y) \\
&= 7/16
\end{align*}
$$
Next, we compute $E(Y \,|\, A = 1)$, 
$$\begin{align*}
E(Y \,|\, A = 1) &= \sum_y y\cdot P(Y=y \,|\, A = 1) \\
&= \sum_y y\cdot \frac{P(Y = y, A = 1)}{P(A = 1)} \\
&= 25/56
\end{align*}
$$
The reason for the difference is that $(Y \,|\, A)$ still allows $Y$ to take values according to different treatment levels: recal $Y = Y_A$. But when we use $Y_a$, we fix our mind on treatment $A = a$ only. 
</p>
<br><br>

<h3 id="Graphical-model-SWIG"><a href="#Graphical-model-SWIG" class="headerlink" title="Graphical model SWIG"></a>Graphical model SWIG</h3><p>To present how variables pass information among each other, we construct a DAG (directed acyclic graph). We denote the set of parent nodes of $X$ by $pa_X$, and parent nodes of $X_i$ by $pa_i$. A very important concept is $\textit{\textbf{Markov compatibility}}$. This says a random variable's distribution only depends on its immediate parent nodes, i.e., other ancester nodes have no effect. Formally speaking, $$P(\bm{x}) = \prod P(x_1 \,|\, pa_i)$$ where $\{X_i\}$ follow a topological ordering (without Markov compatibility, we would need $P(x_i \,|\, x_1, ..., x_{i-1})$.) 
</p>

<hr>
<p> If we decide to assign some treatment levels to variables, we need to construct SWIG (single world intervention graph) (why it's named single world? well, we can only assign one treatment level to a variable at a time). Suppose we assign $\bm{a}$ to a set of variables $A$, then for each variable $X_i \in A$, we split it into two nodes: $X_i$ and $a_i$, denoted as $X_i \,|\, a$. Next, all outgoing arrows from $X_i$ in the original DAG now start from $a_i$. And all incoming arrows to $X_i$ are still kept the same. Finally, we put $X(\bm{a})$ accordingly, meaning we now fix assignment $a$. Below is an example where we assign $a$ to node $A$, 
</p>

<p><img src="/tikz/1.png" loading="lazy"></p>
<p> An important theorem is for $\textit{\textbf{causal irrelevance}}$. Intuitively, it says if I assign values to two groups of nodes $A$ and $B$. If every path from $X_{A\cup B}$ to $Y$ visits $X_A$ after $X_B$, then $$Y(a, b) = Y(a)$$ Below is a picture showing we don't allow path from $X_B$ to $Y$ without going through $X_A$.  
</p>

<p><img src="/tikz/2.png" loading="lazy"></p>
<hr>
<p> Another important concept is $\textbf{\textit{d-separation}}$. 
</p>



<p><br><br><br><br></p>
<blockquote>
<h2 id="Learn-Causal-Inference-via-Papers"><a href="#Learn-Causal-Inference-via-Papers" class="headerlink" title="Learn Causal Inference via Papers"></a>Learn Causal Inference via Papers</h2></blockquote>
<p> I read couple papers that incorporate causal inference, and compiled some key arguments from those papers. Here is the link to my <a href="/documents/introduction_to_Causal_Inference_in_Machine_Learning.pdf">notes</a>, which also serve as the course homework. </p>
</div></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2022/11/10/upcoming-project/" rel="prev" title="Study Notes"><span class="icon iconify" data-icon="ri:arrow-left-s-line"></span><span class="post-nav-text">Study Notes</span></a></div><div class="post-nav-item"></div></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2022 </span><span class="with-love" id="animate"><span class="icon iconify" data-icon="ri:cloud-line"></span></span><span class="author"> Xinta Yang</span></div><div class="powered"><span>Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> v6.3.0</span><span class="footer-separator">|</span><span>Theme - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.10.9</span></div></footer></div><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><span class="icon iconify" data-icon="ri:arrow-up-s-line"></span><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a></body></html>