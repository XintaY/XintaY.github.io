<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="theme-color" content="#579BB1"><meta name="author" content="Xinta Yang"><meta name="copyright" content="Xinta Yang"><meta name="generator" content="Hexo 6.3.0"><meta name="theme" content="hexo-theme-yun"><title>Course STAT 888 - A first exposure to causal inference | </title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/star-markdown-css@0.4.1/dist/yun/yun-markdown.min.css"><link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/prism-theme-vars/base.css"><script src="https://fastly.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>function initScrollReveal() {
  [".post-card",".markdown-body img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
}
document.addEventListener("DOMContentLoaded", initScrollReveal);
document.addEventListener("pjax:success", initScrollReveal);
</script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><link rel="stylesheet" type="text/css" href="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.css"><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><script defer src="https://fastly.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js"></script><script type="module">import { renderKatex } from '/js/utils.js'
document.addEventListener("DOMContentLoaded", () => {
  renderKatex({
    ...{},
    ...true?.options,
  });
});</script><link rel="icon" type="image/png" href="/xy.png"><link rel="mask-icon" href="/xy.png" color="#579BB1"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><link rel="preconnect" href="https://fastly.jsdelivr.net/npm/" crossorigin><script id="yun-config">
    window.Yun = {}
    window.CONFIG = {"hostname":"example.com","root":"/","title":"懒猫的博客","version":"1.10.9","mode":"light","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}.","hits":"${hits} results found","hits_time":"${hits} results found in ${time} ms"},"anonymous_image":"https://cdn.yunyoujun.cn/img/avatar/none.jpg","vendors":{"host":"https://fastly.jsdelivr.net/npm/","darken":"https://fastly.jsdelivr.net/npm/darken@1.5.0"}};
  </script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/hexo-theme-yun.js" type="module"></script><!-- Google Tag Manager --><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-M9KWR9L');</script><!-- End Google Tag Manager --><meta name="description" content="This post is for my STAT 888 course taken at UW-Madison where we study causal inference. As this is my first exposure to the subject, I will not propose anything new; instead, the post merely document">
<meta property="og:type" content="article">
<meta property="og:title" content="Course STAT 888 - A first exposure to causal inference">
<meta property="og:url" content="http://example.com/2022/10/29/causal-inference/index.html">
<meta property="og:site_name">
<meta property="og:description" content="This post is for my STAT 888 course taken at UW-Madison where we study causal inference. As this is my first exposure to the subject, I will not propose anything new; instead, the post merely document">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/tikz/1.png">
<meta property="og:image" content="http://example.com/tikz/2.png">
<meta property="og:image" content="http://example.com/tikz/3.png">
<meta property="og:image" content="http://example.com/tikz/4.png">
<meta property="og:image" content="http://example.com/tikz/5.png">
<meta property="og:image" content="http://example.com/tikz/6.png">
<meta property="article:published_time" content="2022-10-29T15:08:42.000Z">
<meta property="article:modified_time" content="2022-12-23T07:15:36.000Z">
<meta property="article:author" content="Xinta Yang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/tikz/1.png"><script>(function() {
  if (CONFIG.mode !== 'auto') return
  const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
  const setting = localStorage.getItem('darken-mode') || 'auto'
  if (setting === 'dark' || (prefersDark && setting !== 'light'))
    document.documentElement.classList.toggle('dark', true)
})()</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head><body><script src="https://code.iconify.design/2/2.1.1/iconify.min.js"></script><script>// Define global variable
IconifyProviders = {
  // Empty prefix: overwrite default API provider configuration
  '': {
    // Use custom API first, use Iconify public API as backup
    resources: [
        'https://api.iconify.design',
    ],
    // Wait for 1 second before switching API hosts
    rotate: 1000,
  },
};</script><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js" type="module"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="Table of Contents"><span class="icon iconify" data-icon="ri:list-ordered"></span></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="Overview"><span class="icon iconify" data-icon="ri:passport-line"></span></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="Xinta Yang"><img width="96" loading="lazy" src="/images/5.png" alt="Xinta Yang"></a><div class="site-author-name"><a href="/about/">Xinta Yang</a></div><span class="site-name"></span><sub class="site-subtitle">Welcome to my blog! (The characters on the cover page translate to "Lazy cat's blog")</sub><div class="site-description"></div></div><br><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="Home"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:home-4-line"></span></span></a><div class="site-state-item"><a href="mailto:xinta.yang@wisc.edu"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:mail-line"></span></span></a></div><div class="site-state-item"><a target="_blank" rel="noopener" href="https://github.com/XintaY"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:github-line"></span></span></a></div><a class="site-state-item hty-icon-button" href="/tags/" title="Tags"><span class="site-state-item-icon"><span class="icon iconify" data-icon="ri:bookmark-line"></span></span></a></nav><!--hr(style="margin-bottom:0.5rem")--></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Brief-Summary-of-Causal-Inference"><span class="toc-number">1.</span> <span class="toc-text">Brief Summary of Causal Inference</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Potential-outcomes"><span class="toc-number">1.1.</span> <span class="toc-text">Potential outcomes</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Graphical-model-SWIG"><span class="toc-number">1.2.</span> <span class="toc-text">Graphical model SWIG</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Three-identification-theorems"><span class="toc-number">1.3.</span> <span class="toc-text">Three identification theorems</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Estimation-methods"><span class="toc-number">1.4.</span> <span class="toc-text">Estimation methods</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sensitivity-Analysis"><span class="toc-number">1.5.</span> <span class="toc-text">Sensitivity Analysis</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Learn-Causal-Inference-via-Papers"><span class="toc-number">2.</span> <span class="toc-text">Learn Causal Inference via Papers</span></a></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article" style="--smc-primary:#579BB1;"><link itemprop="mainEntityOfPage" href="http://example.com/2022/10/29/causal-inference/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="Xinta Yang"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content=""></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Course STAT 888 - A first exposure to causal inference</h1><div class="post-meta"><div class="post-time"><span class="post-meta-item-icon"><span class="icon iconify" data-icon="ri:calendar-line"></span></span> <time title="Created: 2022-10-29 23:08:42" itemprop="dateCreated datePublished" datetime="2022-10-29T23:08:42+08:00">2022-10-29</time></div><div class="post-classify"></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body"><br>

<p>The whole summary is based on <a target="_blank" rel="noopener" href="https://amy-cochran.gitbook.io/causal-inference/introduction/">Prof. Ane Cochran’s lecture notes</a> <br><br>(To be continued…)</p>
<blockquote>
<h2 id="Brief-Summary-of-Causal-Inference"><a href="#Brief-Summary-of-Causal-Inference" class="headerlink" title="Brief Summary of Causal Inference"></a>Brief Summary of Causal Inference</h2></blockquote>
<h3 id="Potential-outcomes"><a href="#Potential-outcomes" class="headerlink" title="Potential outcomes"></a>Potential outcomes</h3><p> 
Suppose random variable $Y$ is the outcome of an experiment, and random variable $A$ is the corresponding treatment. We assume $\textbf{\textit{consistency}}$, i.e., $$Y(\omega) = Y_A(\omega)$$ We note that each treatment level $a$ associates with a random variable $Y_a$. To be more clear, suppose at event instance $\omega$, we assign treatment $A(\omega) = a$, then consistency says we assume $Y(\omega) = Y_a(\omega)$.
Another important assumption is $\textbf{\textit{exchangeability}}$, i.e., $$Y_a \perp A$$ for all $a \in A$. This says knowing what treatment level assigned does not provide any information about how the subject would react under different treatments. This is usually achieved by randomly assign treatments to subjects. 
We note that not all $Y_a(\omega)$ is observed. For example, if we assign $A = 1$ to subject $\omega$, then we can observe $Y_1(\omega)$, but can't observe $Y_0(\omega)$. 
It's also important to point out that $E(Y_a)$ does not necessarily equal to $E(Y\,|\, A=a)$. For example, 
$$
\begin{array}{c|c|c|c}
X & A & Y & P(x, a, y) \\
\hline
0 & 0 & 0 & 1/8 \\
0 & 0 & 1 & 1/8 \\
0 & 1 & 0 & 1/8 \\
0 & 1 & 1 & 1/8 \\
0 & 1 & 1 & 1/8 \\
1 & 0 & 0 & 25/128 \\
1 & 0 & 1 & 15/128 \\
1 & 1 & 0 & 15/128 \\
1 & 1 & 1 & 9/128
\end{array}
$$
and we also assume here that the potential outcome is invariant to treatment assigned, i.e., $Y_0 = Y_1$. 
By consistency and invariance, we have $Y = Y_0 = Y_1$. 
Hence, $$\begin{align*}
EY_1 &= EY_0 = EY \\
&= \sum_y y\cdot P(Y=y) \\
&= \sum_y y\cdot \sum_{a, x} P(a, x, y) \\
&= 7/16
\end{align*}
$$
Next, we compute $E(Y \,|\, A = 1)$, 
$$\begin{align*}
E(Y \,|\, A = 1) &= \sum_y y\cdot P(Y=y \,|\, A = 1) \\
&= \sum_y y\cdot \frac{P(Y = y, A = 1)}{P(A = 1)} \\
&= 25/56
\end{align*}
$$
The reason for the difference is that $(Y \,|\, A)$ still allows $Y$ to take values according to different treatment levels: recal $Y = Y_A$. But when we use $Y_a$, we fix our mind on treatment $A = a$ only. 
</p>
<br><br>



<h3 id="Graphical-model-SWIG"><a href="#Graphical-model-SWIG" class="headerlink" title="Graphical model SWIG"></a>Graphical model SWIG</h3><p>To present how variables pass information among each other, we construct a DAG (directed acyclic graph). We denote the set of parent nodes of $X$ by $pa_X$, and parent nodes of $X_i$ by $pa_i$. A very important concept is $\textit{\textbf{Markov compatibility}}$. This says a random variable's distribution only depends on its immediate parent nodes, i.e., other ancester nodes have no effect. Formally speaking, $$P(\bm{x}) = \prod P(x_1 \,|\, pa_i)$$ where $\{X_i\}$ follow a topological ordering (without Markov compatibility, we would need $P(x_i \,|\, x_1, ..., x_{i-1})$.) 
</p>

<hr>
<p> If we decide to assign some treatment levels to variables, we need to construct SWIG (single world intervention graph) (why it's named single world? well, we can only assign one treatment level to a variable at a time). Suppose we assign $\bm{a}$ to a set of variables $A$, then for each variable $X_i \in A$, we split it into two nodes: $X_i$ and $a_i$, denoted as $X_i \,|\, a$. Next, all outgoing arrows from $X_i$ in the original DAG now start from $a_i$. And all incoming arrows to $X_i$ are still kept the same. Finally, we put $X(\bm{a})$ accordingly, meaning we now fix assignment $a$. Below is an example where we assign $a$ to node $A$, 
</p>

<p><img src="/tikz/1.png" loading="lazy"></p>
<p> An important theorem is for $\textit{\textbf{causal irrelevance}}$. Suppose I assign values to two groups of nodes $A$ and $B$. If every path from $X_{A\cup B}$ to $Y$ visits $X_A$ after $X_B$ (in the original DAG, not SWIG), then $$Y(a, b) = Y(a)$$ Below is a picture showing we don't allow path from $X_B$ to $Y$ without going through $X_A$.  
</p>

<p><img src="/tikz/2.png" loading="lazy"></p>
<hr>
<p> Another important concept is $\textbf{\textit{d-separation}}$. There are three types of relations among nodes in a SWIG: chain, fork, and collider. They describe how information flows from intervention to outcomes (their structures are shown below.) 
</p>

<p><img src="/tikz/3.png" loading="lazy"></p>
<p> For chain structure, if node $B$ is not intervened, information flows from node $A$ to node $C$. For fork structure, if node $A$ is not intervened, information flows from node $B$ to node $C$. For collider structure, if node $A$ is not intervened, information does $\textit{not}$ flow from node $B$ to node $C$. We say two sets of nodes $\mathcal{A}$ and $\mathcal{B}$ are d-separated if all paths are blocked in term of the three node structures mentioned here. 
</p>
<br><br>



<h3 id="Three-identification-theorems"><a href="#Three-identification-theorems" class="headerlink" title="Three identification theorems"></a>Three identification theorems</h3><p> Now we introduce three theorems that can help to indentify the expectation of the poential outcome. 
The first theorem is $\textbf{\textit{extended g-formula}}$. It says if we assign values to a set of nodes $\mathcal{A}$, then $$E(g(Y_a) \,|\, Y_{pa-\mathcal{A}, \bm{a}} = \bm{x}) = E(g(Y) \,|\, Y_{pa-\mathcal{A}} = \bm{x}, Y_{pa\cap \mathcal{A}} = \bm{a})$$ An example is given here, where $\mathcal{A} = \{A, L\}$ and $\bm{a} = \{a, l\}$, 
</p>

<p><img src="/tikz/4.png" loading="lazy"></p>
<p> An important note is that when invoking the g-formula, we need to measure all parent nodes of $Y$. With the same example above, if we want to estimate $E(Y_{a,l})$, we first need to add some conditions: $E(Y_{a,l} \,|\, X = x)$, and then use the tower property $E(Y) = E(E(Y \,|\, X))$ to finish the computation of $EY$. 
</p>

<hr>
<p> The second widely used theorem is $\textit{\textbf{backdoor adjustment}}$. We first define what are backdoor nodes. Suppose we have two sets of nodes $W$ and $A$, and potential outcome $Y$. We assign $\bm{a}$ to the set of nodes $A$. If $W$ satisfies (1) $A \perp Y_a \,|\, W_a$ in the SWIG; (2) $W_a \perp a$ in the SWIG; then we say $W$ is a set of backdoor nodes w.r.t. $A$ and $Y$. Then, the theorem says, $$E(Y_a) = E(E(Y \,|\, A = a, W))$$ an example is below where $X$ satisfies the backdoor node criteria ($V_a$ does not.) 
</p> 

<p><img src="/tikz/5.png" loading="lazy"></p>
<hr>
<p> The third theorem is $\textbf{\textit{frontdoor adjustment}}$. We still start from the definition of frontdoor  nodes. We say the set $B$ is frontdoor node w.r.t. $(I, J)$ if (1) $J_a \perp a \,|\, B_a$; (2) $I \perp B_a$; (3) $J_b \perp B \,|\, I_b$. In condition (1) and (2), we assign $\bm{a}$ to $I$, and in condition (2), we assign $\bm{b}$ to $B$. Below is a picture of the above criteria from prof. Ane Cochran's lecture notes, 
</p>

<p><img src="/tikz/6.png" loading="lazy"></p>
<p> The theorem then says, $$E(J_a) = E(g(B) \,|\, I = a)$$ where $g(b) = E(E(J \,|\, B = b, I))$. 
</p>
<br><br>



<h3 id="Estimation-methods"><a href="#Estimation-methods" class="headerlink" title="Estimation methods"></a>Estimation methods</h3><p> We first give definitions of empirical expectations. Suppose we observe $n$ data points, denoted as $(X^{(n)}, A^{(n)}, Y^{(n)})$. Define empirical expectation, $$E_N(g(X, A, Y)) = \frac{1}{N}\sum_1^N g(X^{(n)}, A^{(n)}, Y^{(n)})$$ $$E_N(g(X, A, Y) \,|\, h(X, A, Y) = u) = \frac{E_N(g(X, A, Y)\cdot 1_{h(X, A, Y) = u})}{E_N(1_{h(X, A, Y) = u})}$$ The intuition of the conditional expectation is that suppose out of 10 data points, 5 of which has $h(X, A, Y) = u$, and out of those 5 points, 2 of them have $g = 1$ and others have $g = 0$. So the conditional expectation would be $2/5$, and the given formula indeed outputs this value. 
</p>

<hr>
<p> Now consider the simple model with discrete r.v. $X$ as a backdoor node, which leads to $$E(Y_a) = E(E(Y \,|\, A = a, X)) = \sum_x P(X = x)\cdot E(Y \,|\, A = a, X = x) \approx \sum_x P_N(X = x)\cdot E_N(Y \,|\, A = a, X = x)$$ 
We also present an approximated variance of this point estimate (so we may construct confidence interval). Remember we don't consider $X$ and $A$ as random. 
$$
\begin{align*} 
var(E_N(Y \,|\, A = a, X = x)) &= var\left(\frac{E_N(Y\cdot 1_{A = a, X = x})}{E_N(1_{A = a, X = x})} \right) \\
&= \frac{var\left( \sum_i Y_i\cdot 1_{A_i = a, X_i = x} \right)}{N^2P_N^2(A = a, X = x)} \\
&= \frac{\sum_i var(Y_i\cdot 1_{A_i = a, X_i = x})}{N^2P_N^2(A = a, X = x)} \hspace{2em} \text{(by independent r.v. $Y_i$)} \\ 
&= \frac{var(Y \,|\, A = a, X = x)}{NP_N(X = x, A = a)}
\end{align*}
$$
for the last equality, one can check by rearranging the fractions, with $var(Y \,|\, X = x, A = a) = \frac{\frac{1}{N}\cdot \sum_i var(Y_i\cdot 1_{A_i = a, X_i = x})}{P_N(X = x, A = a)}$. This is because we assume $\{Y_i \,|\, A_i = a, X_i = x\}$ are i.i.d. with variance say $\sigma_{(a, x)}^2$. Then, the conditional variance is $\sigma_{(a, x)}^2$, and the fraction here gives exactly this quantity. Note we need to find a way to estimate $var(Y | A = a, X = x)$, and a common choice is to use sample variance of that group as the estimator. 
Now we follow up with an example. Suppose we sampled the weight gain as people age being the following, 
$$
\begin{array}{c|c|c}
& \text{Male } (N = 762) & \text{Female } (N = 804) \\ \hline
\text{Quit} & \text{avg. gain} = 4.83 & 4.16 \\ \hline
\text{Did not quit} & 2.00 & 1.97
\end{array}
$$
so based on the data, we hypothesize that smoking makes it harder to gain weight. Suppose $A$ is whether a person quits smoking (1 means quit, and 0 means not quit), and $X$ is the gender (1 means female, and 0 means male), which acts as a backdoor node. Using the empirical expectation formulae presented above, we have, 
$$
\begin{align*}
E(Y_1 - Y_0) &\approx \sum_{x = 0, 1} P_N(X = x)\cdot (E_N(Y \,|\, A = 1, X = x) - E_N(Y \,|\, A = 0, X = x)) \\ 
&= \frac{762}{1566}\cdot (4.83 - 2.00) + \frac{804}{1566}\cdot (4.16 - 1.97) \\
&= 2.50
\end{align*}
$$
</p>

<hr>
<p> For discrete r.v. we can use the empirical expectation formulae presented above, but for continuous r.v., it's harder. So, we introduce $\textit{\textbf{outcome regression}}$ method. 
The general idea is to first propose a function $\mu_\theta(X, A)$ with some unknown parameters $\theta$, that has $$\mu_\theta(X, A) = E(Y \,|\, X, A)$$ Then we find some best fit $\hat{\theta}$, and use $$E(Y_a) \approx E_N(\mu_{\hat{\theta}}(X, a))$$ The choice of $\mu$ is totally upto us, some common choices are linear models and neural networks. And then the fitting of $\hat{\theta}$ can be taken as $$\hat{\theta} = \argmin_\theta E_N(Y - \mu_\theta(X, A))^2$$
Now we provide an example of linear model. Suppose $\mu_\theta(X, A) = (X \,\, A)\theta$, where $\theta = (\theta_1 \,\, \theta_2)^T$. Then, 
$$\hat{\theta} = \argmin_\theta E_N(Y - (X \,\, A)\theta)^2$$ implies $\hat{\theta}$ satisfies, 
$$E_N((Y - (X \,\, A)\hat{\theta})\cdot (X \,\, A)) = 0$$ 
Here $X$ and $A$ can be both scalers or vectors (if they are vectors, then $\theta_1$ and $\theta_2$ are both vectors too.)
</p>

<hr>
<p> Next, we discuss $\textit{\textbf{propensity score}}$ approach. 
</p>



<p><br><br></p>
<h3 id="Sensitivity-Analysis"><a href="#Sensitivity-Analysis" class="headerlink" title="Sensitivity Analysis"></a>Sensitivity Analysis</h3><p><br><br><br><br></p>
<blockquote>
<h2 id="Learn-Causal-Inference-via-Papers"><a href="#Learn-Causal-Inference-via-Papers" class="headerlink" title="Learn Causal Inference via Papers"></a>Learn Causal Inference via Papers</h2></blockquote>
<p> I read couple papers that incorporate causal inference, and compiled some key arguments from those papers. Here is the link to my <a href="/documents/introduction_to_Causal_Inference_in_Machine_Learning.pdf">notes</a>, which also serve as the course homework. </p>
</div></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2023/03/10/TDA/" rel="prev" title="A quick overview of TDA"><span class="icon iconify" data-icon="ri:arrow-left-s-line"></span><span class="post-nav-text">A quick overview of TDA</span></a></div><div class="post-nav-item"></div></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2022 – 2024 </span><span class="with-love" id="animate"><span class="icon iconify" data-icon="ri:cloud-line"></span></span><span class="author"> Xinta Yang</span></div><div class="powered"><span>Powered by <a href="https://hexo.io" target="_blank" rel="noopener">Hexo</a> v6.3.0</span><span class="footer-separator">|</span><span>Theme - <a rel="noopener" href="https://github.com/YunYouJun/hexo-theme-yun" target="_blank"><span>Yun</span></a> v1.10.9</span></div></footer></div><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><span class="icon iconify" data-icon="ri:arrow-up-s-line"></span><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#579BB1" stroke-width="2" stroke-linecap="round"></circle></svg></a></body></html>